{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter\n",
    "from http://help.sentiment140.com/for-students/\n",
    "\n",
    "The data is a CSV with emoticons removed. Data file format has 6 fields:  \n",
    "0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)  \n",
    "1 - the id of the tweet (2087)  \n",
    "2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)  \n",
    "3 - the query (lyx). If there is no query, then this value is NO_QUERY.  \n",
    "4 - the user that tweeted (robotickilldozr)  \n",
    "5 - the text of the tweet (Lyx is cool)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:imported term dicts: prons_m2f, prons_f2m, terms_m2f, terms_f2m; and sets; all_prons and all_terms\n",
      "INFO:root:successfully imported the latest version of data_masking.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, pickle, xlsxwriter\n",
    "# sys.path.append(\"/home/jent_so/LM_GenderBias\")\n",
    "# sys.path.append(\"/home/jent_so/LM_GenderBias/terms\")\n",
    "\n",
    "import pandas as pd\n",
    "import data_masking as masking\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "# create logger\n",
    "logger_twitter_prep = logging.getLogger('twitter_prep')\n",
    "logger_twitter_prep.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(reviews):\n",
    "    reviews = [re.sub('@[^\\s]+','', line) for line in reviews]\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:!?,\\\"()\\[\\]]\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)|(\\')\")\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into test and training set\n",
    "(!) Only once in the initialisation to keep the sets constant"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Attantion!!! Compile with caution. This will change the partition of training/test set \n",
    "\n",
    "df = pd.read_csv('Twitter_raw_data/training.1600000.processed.noemoticon.csv', encoding='latin-1', names= ['sentiment','ID','date','query','user','text_raw']) \n",
    "\n",
    "shuffled = df.sample(frac=1)\n",
    "result = np.array_split(shuffled, 2)\n",
    "\n",
    "print(len(result[0]))  # 800000\n",
    "print(len(result[1]))  # 800000\n",
    "\n",
    "type(result[1]) # <class 'pandas.core.frame.DataFrame'>\n",
    "    \n",
    "with open('Twitter_train_raw', \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(result[0], fp)\n",
    "with open('Twitter_test_raw', \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(result[1], fp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test that no neutrals are included\n",
    "df_train = train[train['sentiment'] != 2]\n",
    "df_test = test[test['sentiment'] != 2]\n",
    "print(len(train), len(test))\n",
    "print(len(df_train), len(df_test))\n",
    "\n",
    "print(df_test.shape == test.shape)\n",
    "print(df_train.shape == train.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train_complete = pd.read_pickle('Twitter_raw_data/Twitter_train_raw')\n",
    "df_test_complete = pd.read_pickle('Twitter_raw_data/Twitter_test_raw')\n",
    "\n",
    "df_train_complete.ID = 'train_'+ df_train_complete['sentiment'].astype(str) +'_'+ df_train_complete['ID'].astype(str)\n",
    "df_test_complete.ID = 'test_'+ df_test_complete['sentiment'].astype(str) +'_'+ df_test_complete['ID'].astype(str)\n",
    "\n",
    "df_train_complete.insert(1, 'text', clean_text(df_train_complete.text_raw.tolist()), True)\n",
    "df_test_complete.insert(1, 'text', clean_text(df_test_complete.text_raw.tolist()), True)\n",
    "\n",
    "df_train = df_train_complete[['ID', 'text', 'sentiment']].rename({'sentiment': 'label'}, axis=1)\n",
    "df_test = df_test_complete[['ID', 'text', 'sentiment']].rename({'sentiment': 'label'}, axis=1)\n",
    "\n",
    "df_train.to_pickle('Twitter_training/Twitter_train')\n",
    "df_test.to_pickle('Twitter_training/Twitter_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('Twitter_training/Twitter_train')\n",
    "df_test = pd.read_pickle('Twitter_training/Twitter_test')\n",
    "df_train\n",
    "\n",
    "df_train_ = pd.read_pickle(\"Twitter_l_train\")\n",
    "df_test_ = pd.read_pickle(\"Twitter_l_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('Twitter_training/Twitter_original_train')\n",
    "df_test.to_pickle('Twitter_training/Twitter_original_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524045</th>\n",
       "      <td>train_0_2193340125</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503517</th>\n",
       "      <td>train_4_2071990209</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675911</th>\n",
       "      <td>train_0_2248238260</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175180</th>\n",
       "      <td>train_4_1981058341</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639764</th>\n",
       "      <td>train_0_2234803784</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190129</th>\n",
       "      <td>train_4_1983659245</td>\n",
       "      <td>made it to la everyone look for me at the movi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565965</th>\n",
       "      <td>train_4_2187664366</td>\n",
       "      <td>it s going to be good for sure  and the new  ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598193</th>\n",
       "      <td>train_4_2193121036</td>\n",
       "      <td>expand please</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020558</th>\n",
       "      <td>train_4_1882388002</td>\n",
       "      <td>#followfriday  an awesome mom friend and all a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196830</th>\n",
       "      <td>train_4_1984865161</td>\n",
       "      <td>im glad your friend is ok</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID  \\\n",
       "524045   train_0_2193340125   \n",
       "1503517  train_4_2071990209   \n",
       "675911   train_0_2248238260   \n",
       "1175180  train_4_1981058341   \n",
       "639764   train_0_2234803784   \n",
       "...                     ...   \n",
       "1190129  train_4_1983659245   \n",
       "1565965  train_4_2187664366   \n",
       "1598193  train_4_2193121036   \n",
       "1020558  train_4_1882388002   \n",
       "1196830  train_4_1984865161   \n",
       "\n",
       "                                                      text  label  \n",
       "524045    i really wanna see you in glasgow tomorrow bu...      0  \n",
       "1503517  getting ready to hit the sack 315 comes around...      4  \n",
       "675911   i realized tomorrow is my last dance recital e...      0  \n",
       "1175180  at the salon doing make up for a shoot at  tod...      4  \n",
       "639764      school photos chemistry retake not a good day       0  \n",
       "...                                                    ...    ...  \n",
       "1190129  made it to la everyone look for me at the movi...      4  \n",
       "1565965   it s going to be good for sure  and the new  ...      4  \n",
       "1598193                                     expand please       4  \n",
       "1020558  #followfriday  an awesome mom friend and all a...      4  \n",
       "1196830                         im glad your friend is ok       4  \n",
       "\n",
       "[800000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1390936</th>\n",
       "      <td>test_4_2053270644</td>\n",
       "      <td>its a boring day and i need a boring movie to ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314870</th>\n",
       "      <td>test_4_2013961964</td>\n",
       "      <td>thank god they brought back the deep voice guy...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606001</th>\n",
       "      <td>test_0_2222443228</td>\n",
       "      <td>sad news the spice flow came to an end   http ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101957</th>\n",
       "      <td>test_0_1794727393</td>\n",
       "      <td>im usually a fighter but its kind of hard to f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656613</th>\n",
       "      <td>test_0_2240575304</td>\n",
       "      <td>my brother and i miss you over at facebook</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912730</th>\n",
       "      <td>test_4_1752384224</td>\n",
       "      <td>round 2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675598</th>\n",
       "      <td>test_0_2248143215</td>\n",
       "      <td>red lobster makes me so sick to my stomach ev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121880</th>\n",
       "      <td>test_0_1833604010</td>\n",
       "      <td>i m freaking tired i m nervous about tomorrow ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453206</th>\n",
       "      <td>test_4_2063209643</td>\n",
       "      <td>i couldnt agree with you more</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323492</th>\n",
       "      <td>test_4_2014908349</td>\n",
       "      <td>have fun  wanna meet up later</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID                                               text  \\\n",
       "1390936  test_4_2053270644  its a boring day and i need a boring movie to ...   \n",
       "1314870  test_4_2013961964  thank god they brought back the deep voice guy...   \n",
       "606001   test_0_2222443228  sad news the spice flow came to an end   http ...   \n",
       "101957   test_0_1794727393  im usually a fighter but its kind of hard to f...   \n",
       "656613   test_0_2240575304       my brother and i miss you over at facebook     \n",
       "...                    ...                                                ...   \n",
       "912730   test_4_1752384224                                           round 2    \n",
       "675598   test_0_2248143215   red lobster makes me so sick to my stomach ev...   \n",
       "121880   test_0_1833604010  i m freaking tired i m nervous about tomorrow ...   \n",
       "1453206  test_4_2063209643                     i couldnt agree with you more    \n",
       "1323492  test_4_2014908349                      have fun  wanna meet up later   \n",
       "\n",
       "         label  \n",
       "1390936      4  \n",
       "1314870      4  \n",
       "606001       0  \n",
       "101957       0  \n",
       "656613       0  \n",
       "...        ...  \n",
       "912730       4  \n",
       "675598       0  \n",
       "121880       0  \n",
       "1453206      4  \n",
       "1323492      4  \n",
       "\n",
       "[800000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "---  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Gender neutral data sets for training\n",
    "\n",
    "- condition 1: **remove** gender terms - `_N`\n",
    "- condition 2: **replace** and use both - `_M + _F`  \n",
    "\n",
    "- three different dicts: (1) all = big dict terms (2) weat = dict only contains WEAT target terms (3) prons = dict only contains pronouns as target terms  \n",
    "`text_all_M` | `text_all_F` | `text_all_N`  \n",
    "`text_weat_M` | `text_weat_F` | `text_weat_N`  \n",
    "`text_pron_M` | `text_pron_F` | `text_pron_N`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: make_all_df: finish counts and length\n",
      "INFO:root: make_all_df: finish text_all_M\n",
      "INFO:root: make_all_df: finish text_all_F\n",
      "INFO:root: make_all_df: finish text_all_N\n",
      "INFO:root: make_all_df: finish text_weat_M\n",
      "INFO:root: make_all_df: finish text_weat_F\n",
      "INFO:root: make_all_df: finish text_weat_N\n",
      "INFO:root: make_all_df: finish text_pro_M\n",
      "INFO:root: make_all_df: finish text_pro_F\n",
      "INFO:root: make_all_df: finish text_pro_N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         ID  \\\n",
      "524045   train_0_2193340125   \n",
      "1503517  train_4_2071990209   \n",
      "\n",
      "                                                      text  label  \\\n",
      "524045    i really wanna see you in glasgow tomorrow bu...      0   \n",
      "1503517  getting ready to hit the sack 315 comes around...      4   \n",
      "\n",
      "                                               count_table  count_total  \\\n",
      "524045   {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
      "1503517  {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
      "\n",
      "                                          count_table_weat  count_weat  \\\n",
      "524045   {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
      "1503517  {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
      "\n",
      "         count_prons  len                                         text_all_M  \\\n",
      "524045             0   14   i really wanna see you in glasgow tomorrow bu...   \n",
      "1503517            0   12  getting ready to hit the sack 315 comes around...   \n",
      "\n",
      "                                                text_all_F  \\\n",
      "524045    i really wanna see you in glasgow tomorrow bu...   \n",
      "1503517  getting ready to hit the sack 315 comes around...   \n",
      "\n",
      "                                                text_all_N  \\\n",
      "524045    i really wanna see you in glasgow tomorrow bu...   \n",
      "1503517  getting ready to hit the sack 315 comes around...   \n",
      "\n",
      "                                               text_weat_M  \\\n",
      "524045    i really wanna see you in glasgow tomorrow bu...   \n",
      "1503517  getting ready to hit the sack 315 comes around...   \n",
      "\n",
      "                                               text_weat_F  \\\n",
      "524045    i really wanna see you in glasgow tomorrow bu...   \n",
      "1503517  getting ready to hit the sack 315 comes around...   \n",
      "\n",
      "                                               text_weat_N  \\\n",
      "524045    i really wanna see you in glasgow tomorrow bu...   \n",
      "1503517  getting ready to hit the sack 315 comes around...   \n",
      "\n",
      "                                                text_pro_M  \\\n",
      "524045    i really wanna see you in glasgow tomorrow bu...   \n",
      "1503517  getting ready to hit the sack 315 comes around...   \n",
      "\n",
      "                                                text_pro_F  \\\n",
      "524045    i really wanna see you in glasgow tomorrow bu...   \n",
      "1503517  getting ready to hit the sack 315 comes around...   \n",
      "\n",
      "                                                text_pro_N  \n",
      "524045    i really wanna see you in glasgow tomorrow bu...  \n",
      "1503517  getting ready to hit the sack 315 comes around...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: make_all_df: finish counts and length\n",
      "INFO:root: make_all_df: finish text_all_M\n",
      "INFO:root: make_all_df: finish text_all_F\n",
      "INFO:root: make_all_df: finish text_all_N\n",
      "INFO:root: make_all_df: finish text_weat_M\n",
      "INFO:root: make_all_df: finish text_weat_F\n",
      "INFO:root: make_all_df: finish text_weat_N\n",
      "INFO:root: make_all_df: finish text_pro_M\n",
      "INFO:root: make_all_df: finish text_pro_F\n",
      "INFO:root: make_all_df: finish text_pro_N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        ID                                               text  \\\n",
      "1390936  test_4_2053270644  its a boring day and i need a boring movie to ...   \n",
      "1314870  test_4_2013961964  thank god they brought back the deep voice guy...   \n",
      "\n",
      "         label                                        count_table  \\\n",
      "1390936      4  {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...   \n",
      "1314870      4  {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...   \n",
      "\n",
      "         count_total                                   count_table_weat  \\\n",
      "1390936            0  {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...   \n",
      "1314870            2  {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...   \n",
      "\n",
      "         count_weat  count_prons  len  \\\n",
      "1390936           0            0   26   \n",
      "1314870           0            0   15   \n",
      "\n",
      "                                                text_all_M  \\\n",
      "1390936  its a boring day and i need a boring movie to ...   \n",
      "1314870  thank god they brought back the deep voice guy...   \n",
      "\n",
      "                                                text_all_F  \\\n",
      "1390936  its a boring day and i need a boring movie to ...   \n",
      "1314870  thank goddess they brought back the deep voice...   \n",
      "\n",
      "                                                text_all_N  \\\n",
      "1390936  its a boring day and i need a boring movie to ...   \n",
      "1314870  thank they brought back the deep voice to do t...   \n",
      "\n",
      "                                               text_weat_M  \\\n",
      "1390936  its a boring day and i need a boring movie to ...   \n",
      "1314870  thank god they brought back the deep voice guy...   \n",
      "\n",
      "                                               text_weat_F  \\\n",
      "1390936  its a boring day and i need a boring movie to ...   \n",
      "1314870  thank god they brought back the deep voice guy...   \n",
      "\n",
      "                                               text_weat_N  \\\n",
      "1390936  its a boring day and i need a boring movie to ...   \n",
      "1314870  thank god they brought back the deep voice guy...   \n",
      "\n",
      "                                                text_pro_M  \\\n",
      "1390936  its a boring day and i need a boring movie to ...   \n",
      "1314870  thank god they brought back the deep voice guy...   \n",
      "\n",
      "                                                text_pro_F  \\\n",
      "1390936  its a boring day and i need a boring movie to ...   \n",
      "1314870  thank god they brought back the deep voice guy...   \n",
      "\n",
      "                                                text_pro_N  \n",
      "1390936  its a boring day and i need a boring movie to ...  \n",
      "1314870  thank god they brought back the deep voice guy...  \n"
     ]
    }
   ],
   "source": [
    "# Mask all terms in Data \n",
    "\n",
    "df_train_ = df_train.copy()\n",
    "df_test_ = df_test.copy()\n",
    "\n",
    "masking.make_all_df(df_train_)\n",
    "print(df_train_.head(2))\n",
    "\n",
    "masking.make_all_df(df_test_)\n",
    "print(df_test_.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:all tests ok\n",
      "INFO:root:all tests ok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 18)\n",
      "(800000, 18)\n"
     ]
    }
   ],
   "source": [
    "masking.check_df(df_test_)\n",
    "masking.check_df(df_train_)\n",
    "\n",
    "print(df_train_.shape)\n",
    "print(df_test_.shape)\n",
    "\n",
    "# Safe whole table (large)\n",
    "df_train_.to_pickle(\"Twitter_l_train\")\n",
    "df_test_.to_pickle(\"Twitter_l_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524045</th>\n",
       "      <td>train_0_2193340125</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503517</th>\n",
       "      <td>train_4_2071990209</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID  \\\n",
       "524045   train_0_2193340125   \n",
       "1503517  train_4_2071990209   \n",
       "\n",
       "                                                      text  label  \n",
       "524045    i really wanna see you in glasgow tomorrow bu...      0  \n",
       "1503517  getting ready to hit the sack 315 comes around...      4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>count_table</th>\n",
       "      <th>count_total</th>\n",
       "      <th>count_table_weat</th>\n",
       "      <th>count_weat</th>\n",
       "      <th>count_prons</th>\n",
       "      <th>len</th>\n",
       "      <th>text_all_M</th>\n",
       "      <th>text_all_F</th>\n",
       "      <th>text_all_N</th>\n",
       "      <th>text_weat_M</th>\n",
       "      <th>text_weat_F</th>\n",
       "      <th>text_weat_N</th>\n",
       "      <th>text_pro_M</th>\n",
       "      <th>text_pro_F</th>\n",
       "      <th>text_pro_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524045</th>\n",
       "      <td>train_0_2193340125</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'bondman': 0, 'stewardess': 0, 'girlhood': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'men': 0, 'girl': 0, 'grandmother': 0, 'femin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "      <td>i really wanna see you in glasgow tomorrow bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503517</th>\n",
       "      <td>train_4_2071990209</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bondman': 0, 'stewardess': 0, 'girlhood': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'men': 0, 'girl': 0, 'grandmother': 0, 'femin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "      <td>getting ready to hit the sack 315 comes around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675911</th>\n",
       "      <td>train_0_2248238260</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'bondman': 0, 'stewardess': 0, 'girlhood': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'men': 0, 'girl': 0, 'grandmother': 0, 'femin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "      <td>i realized tomorrow is my last dance recital e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175180</th>\n",
       "      <td>train_4_1981058341</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bondman': 0, 'stewardess': 0, 'girlhood': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'men': 0, 'girl': 0, 'grandmother': 0, 'femin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "      <td>at the salon doing make up for a shoot at  tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639764</th>\n",
       "      <td>train_0_2234803784</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "      <td>0</td>\n",
       "      <td>{'bondman': 0, 'stewardess': 0, 'girlhood': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'men': 0, 'girl': 0, 'grandmother': 0, 'femin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "      <td>school photos chemistry retake not a good day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494174</th>\n",
       "      <td>train_4_2069640838</td>\n",
       "      <td>just go to your bank and file a unauthorized ...</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bondman': 0, 'stewardess': 0, 'girlhood': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'men': 0, 'girl': 0, 'grandmother': 0, 'femin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>just go to your bank and file a unauthorized ...</td>\n",
       "      <td>just go to your bank and file a unauthorized ...</td>\n",
       "      <td>just go to your bank and file a unauthorized ...</td>\n",
       "      <td>just go to your bank and file a unauthorized ...</td>\n",
       "      <td>just go to your bank and file a unauthorized ...</td>\n",
       "      <td>just go to your bank and file a unauthorized ...</td>\n",
       "      <td>just go to your bank and file a unauthorized ...</td>\n",
       "      <td>just go to your bank and file a unauthorized ...</td>\n",
       "      <td>just go to your bank and file a unauthorized ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958640</th>\n",
       "      <td>train_4_1825796772</td>\n",
       "      <td>i know you ve got a link that will explain wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bondman': 0, 'stewardess': 0, 'girlhood': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'men': 0, 'girl': 0, 'grandmother': 0, 'femin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>i know you ve got a link that will explain wh...</td>\n",
       "      <td>i know you ve got a link that will explain wh...</td>\n",
       "      <td>i know you ve got a link that will explain wh...</td>\n",
       "      <td>i know you ve got a link that will explain wh...</td>\n",
       "      <td>i know you ve got a link that will explain wh...</td>\n",
       "      <td>i know you ve got a link that will explain wh...</td>\n",
       "      <td>i know you ve got a link that will explain wh...</td>\n",
       "      <td>i know you ve got a link that will explain wh...</td>\n",
       "      <td>i know you ve got a link that will explain wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497279</th>\n",
       "      <td>train_4_2070346069</td>\n",
       "      <td>been listening to your cd a lot while chillin...</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bondman': 0, 'stewardess': 0, 'girlhood': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'men': 0, 'girl': 0, 'grandmother': 0, 'femin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>been listening to your cd a lot while chillin...</td>\n",
       "      <td>been listening to your cd a lot while chillin...</td>\n",
       "      <td>been listening to your cd a lot while chillin...</td>\n",
       "      <td>been listening to your cd a lot while chillin...</td>\n",
       "      <td>been listening to your cd a lot while chillin...</td>\n",
       "      <td>been listening to your cd a lot while chillin...</td>\n",
       "      <td>been listening to your cd a lot while chillin...</td>\n",
       "      <td>been listening to your cd a lot while chillin...</td>\n",
       "      <td>been listening to your cd a lot while chillin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496267</th>\n",
       "      <td>train_4_2070090243</td>\n",
       "      <td>headin 4 de bedactually i m in de bedbut mah e...</td>\n",
       "      <td>4</td>\n",
       "      <td>{'bondman': 0, 'stewardess': 0, 'girlhood': 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'men': 0, 'girl': 0, 'grandmother': 0, 'femin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>headin 4 de bedactually i m in de bedbut mah e...</td>\n",
       "      <td>headin 4 de bedactually i m in de bedbut mah e...</td>\n",
       "      <td>headin 4 de bedactually i m in de bedbut mah e...</td>\n",
       "      <td>headin 4 de bedactually i m in de bedbut mah e...</td>\n",
       "      <td>headin 4 de bedactually i m in de bedbut mah e...</td>\n",
       "      <td>headin 4 de bedactually i m in de bedbut mah e...</td>\n",
       "      <td>headin 4 de bedactually i m in de bedbut mah e...</td>\n",
       "      <td>headin 4 de bedactually i m in de bedbut mah e...</td>\n",
       "      <td>headin 4 de bedactually i m in de bedbut mah e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547452</th>\n",
       "      <td>train_0_2202079302</td>\n",
       "      <td>i watched jada s new show hawthorn i wasn t im...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'bondman': 0, 'stewardess': 0, 'girlhood': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'men': 0, 'girl': 0, 'grandmother': 0, 'femin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>i watched jada s new show hawthorn i wasn t im...</td>\n",
       "      <td>i watched jada s new show hawthorn i wasn t im...</td>\n",
       "      <td>i watched jada s new show hawthorn i wasn t im...</td>\n",
       "      <td>i watched jada s new show hawthorn i wasn t im...</td>\n",
       "      <td>i watched jada s new show hawthorn i wasn t im...</td>\n",
       "      <td>i watched jada s new show hawthorn i wasn t im...</td>\n",
       "      <td>i watched jada s new show hawthorn i wasn t im...</td>\n",
       "      <td>i watched jada s new show hawthorn i wasn t im...</td>\n",
       "      <td>i watched jada s new show hawthorn i wasn t im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID  \\\n",
       "524045   train_0_2193340125   \n",
       "1503517  train_4_2071990209   \n",
       "675911   train_0_2248238260   \n",
       "1175180  train_4_1981058341   \n",
       "639764   train_0_2234803784   \n",
       "1494174  train_4_2069640838   \n",
       "958640   train_4_1825796772   \n",
       "1497279  train_4_2070346069   \n",
       "1496267  train_4_2070090243   \n",
       "547452   train_0_2202079302   \n",
       "\n",
       "                                                      text  label  \\\n",
       "524045    i really wanna see you in glasgow tomorrow bu...      0   \n",
       "1503517  getting ready to hit the sack 315 comes around...      4   \n",
       "675911   i realized tomorrow is my last dance recital e...      0   \n",
       "1175180  at the salon doing make up for a shoot at  tod...      4   \n",
       "639764      school photos chemistry retake not a good day       0   \n",
       "1494174   just go to your bank and file a unauthorized ...      4   \n",
       "958640    i know you ve got a link that will explain wh...      4   \n",
       "1497279   been listening to your cd a lot while chillin...      4   \n",
       "1496267  headin 4 de bedactually i m in de bedbut mah e...      4   \n",
       "547452   i watched jada s new show hawthorn i wasn t im...      0   \n",
       "\n",
       "                                               count_table  count_total  \\\n",
       "524045   {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
       "1503517  {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
       "675911   {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
       "1175180  {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
       "639764   {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
       "1494174  {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
       "958640   {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
       "1497279  {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
       "1496267  {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            1   \n",
       "547452   {'bondman': 0, 'stewardess': 0, 'girlhood': 0,...            0   \n",
       "\n",
       "                                          count_table_weat  count_weat  \\\n",
       "524045   {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
       "1503517  {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
       "675911   {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
       "1175180  {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
       "639764   {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
       "1494174  {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
       "958640   {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
       "1497279  {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
       "1496267  {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
       "547452   {'men': 0, 'girl': 0, 'grandmother': 0, 'femin...           0   \n",
       "\n",
       "         count_prons  len                                         text_all_M  \\\n",
       "524045             0   14   i really wanna see you in glasgow tomorrow bu...   \n",
       "1503517            0   12  getting ready to hit the sack 315 comes around...   \n",
       "675911             0   12  i realized tomorrow is my last dance recital e...   \n",
       "1175180            0   11  at the salon doing make up for a shoot at  tod...   \n",
       "639764             0    8     school photos chemistry retake not a good day    \n",
       "1494174            0   17   just go to your bank and file a unauthorized ...   \n",
       "958640             0   28   i know you ve got a link that will explain wh...   \n",
       "1497279            0   17   been listening to your cd a lot while chillin...   \n",
       "1496267            0   31  headin 4 de bedactually i m in de bedbut mah e...   \n",
       "547452             0   17  i watched jada s new show hawthorn i wasn t im...   \n",
       "\n",
       "                                                text_all_F  \\\n",
       "524045    i really wanna see you in glasgow tomorrow bu...   \n",
       "1503517  getting ready to hit the sack 315 comes around...   \n",
       "675911   i realized tomorrow is my last dance recital e...   \n",
       "1175180  at the salon doing make up for a shoot at  tod...   \n",
       "639764      school photos chemistry retake not a good day    \n",
       "1494174   just go to your bank and file a unauthorized ...   \n",
       "958640    i know you ve got a link that will explain wh...   \n",
       "1497279   been listening to your cd a lot while chillin...   \n",
       "1496267  headin 4 de bedactually i m in de bedbut mah e...   \n",
       "547452   i watched jada s new show hawthorn i wasn t im...   \n",
       "\n",
       "                                                text_all_N  \\\n",
       "524045    i really wanna see you in glasgow tomorrow bu...   \n",
       "1503517  getting ready to hit the sack 315 comes around...   \n",
       "675911   i realized tomorrow is my last dance recital e...   \n",
       "1175180  at the salon doing make up for a shoot at  tod...   \n",
       "639764      school photos chemistry retake not a good day    \n",
       "1494174   just go to your bank and file a unauthorized ...   \n",
       "958640    i know you ve got a link that will explain wh...   \n",
       "1497279   been listening to your cd a lot while chillin...   \n",
       "1496267  headin 4 de bedactually i m in de bedbut mah e...   \n",
       "547452   i watched jada s new show hawthorn i wasn t im...   \n",
       "\n",
       "                                               text_weat_M  \\\n",
       "524045    i really wanna see you in glasgow tomorrow bu...   \n",
       "1503517  getting ready to hit the sack 315 comes around...   \n",
       "675911   i realized tomorrow is my last dance recital e...   \n",
       "1175180  at the salon doing make up for a shoot at  tod...   \n",
       "639764      school photos chemistry retake not a good day    \n",
       "1494174   just go to your bank and file a unauthorized ...   \n",
       "958640    i know you ve got a link that will explain wh...   \n",
       "1497279   been listening to your cd a lot while chillin...   \n",
       "1496267  headin 4 de bedactually i m in de bedbut mah e...   \n",
       "547452   i watched jada s new show hawthorn i wasn t im...   \n",
       "\n",
       "                                               text_weat_F  \\\n",
       "524045    i really wanna see you in glasgow tomorrow bu...   \n",
       "1503517  getting ready to hit the sack 315 comes around...   \n",
       "675911   i realized tomorrow is my last dance recital e...   \n",
       "1175180  at the salon doing make up for a shoot at  tod...   \n",
       "639764      school photos chemistry retake not a good day    \n",
       "1494174   just go to your bank and file a unauthorized ...   \n",
       "958640    i know you ve got a link that will explain wh...   \n",
       "1497279   been listening to your cd a lot while chillin...   \n",
       "1496267  headin 4 de bedactually i m in de bedbut mah e...   \n",
       "547452   i watched jada s new show hawthorn i wasn t im...   \n",
       "\n",
       "                                               text_weat_N  \\\n",
       "524045    i really wanna see you in glasgow tomorrow bu...   \n",
       "1503517  getting ready to hit the sack 315 comes around...   \n",
       "675911   i realized tomorrow is my last dance recital e...   \n",
       "1175180  at the salon doing make up for a shoot at  tod...   \n",
       "639764      school photos chemistry retake not a good day    \n",
       "1494174   just go to your bank and file a unauthorized ...   \n",
       "958640    i know you ve got a link that will explain wh...   \n",
       "1497279   been listening to your cd a lot while chillin...   \n",
       "1496267  headin 4 de bedactually i m in de bedbut mah e...   \n",
       "547452   i watched jada s new show hawthorn i wasn t im...   \n",
       "\n",
       "                                                text_pro_M  \\\n",
       "524045    i really wanna see you in glasgow tomorrow bu...   \n",
       "1503517  getting ready to hit the sack 315 comes around...   \n",
       "675911   i realized tomorrow is my last dance recital e...   \n",
       "1175180  at the salon doing make up for a shoot at  tod...   \n",
       "639764      school photos chemistry retake not a good day    \n",
       "1494174   just go to your bank and file a unauthorized ...   \n",
       "958640    i know you ve got a link that will explain wh...   \n",
       "1497279   been listening to your cd a lot while chillin...   \n",
       "1496267  headin 4 de bedactually i m in de bedbut mah e...   \n",
       "547452   i watched jada s new show hawthorn i wasn t im...   \n",
       "\n",
       "                                                text_pro_F  \\\n",
       "524045    i really wanna see you in glasgow tomorrow bu...   \n",
       "1503517  getting ready to hit the sack 315 comes around...   \n",
       "675911   i realized tomorrow is my last dance recital e...   \n",
       "1175180  at the salon doing make up for a shoot at  tod...   \n",
       "639764      school photos chemistry retake not a good day    \n",
       "1494174   just go to your bank and file a unauthorized ...   \n",
       "958640    i know you ve got a link that will explain wh...   \n",
       "1497279   been listening to your cd a lot while chillin...   \n",
       "1496267  headin 4 de bedactually i m in de bedbut mah e...   \n",
       "547452   i watched jada s new show hawthorn i wasn t im...   \n",
       "\n",
       "                                                text_pro_N  \n",
       "524045    i really wanna see you in glasgow tomorrow bu...  \n",
       "1503517  getting ready to hit the sack 315 comes around...  \n",
       "675911   i realized tomorrow is my last dance recital e...  \n",
       "1175180  at the salon doing make up for a shoot at  tod...  \n",
       "639764      school photos chemistry retake not a good day   \n",
       "1494174   just go to your bank and file a unauthorized ...  \n",
       "958640    i know you ve got a link that will explain wh...  \n",
       "1497279   been listening to your cd a lot while chillin...  \n",
       "1496267  headin 4 de bedactually i m in de bedbut mah e...  \n",
       "547452   i watched jada s new show hawthorn i wasn t im...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108800, 18)\n",
      "(800000, 18)\n"
     ]
    }
   ],
   "source": [
    "# We see that 7/8 of the samples has no term included\n",
    "\n",
    "print(df_train_[df_train_['count_total']> 0].shape) \n",
    "print(df_train_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the large table, we now produce specific test and  training sets \n",
    "\n",
    "Safe training and test dataframes for different training conditions.  \n",
    "neutral and mixed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 3) (1600000, 3)\n",
      "(1600000, 3) (1600000, 3)\n",
      "(1600000, 3) (1600000, 3)\n"
     ]
    }
   ],
   "source": [
    "# neutral\n",
    "for spec in ['_all', '_pro', '_weat']:\n",
    "    df_train_[['ID', 'text'+spec+'_N', 'label']].to_pickle('Twitter_training/Twitter_N'+spec+'_train')\n",
    "    df_test_[['ID', 'text'+spec+'_N', 'label']].to_pickle('Twitter_training/Twitter_N'+spec+'_test')\n",
    "\n",
    "# mixed M+F\n",
    "for spec in ['_all', '_pro', '_weat']: \n",
    "    m_tr = df_train_[['ID', 'text'+spec+'_M', 'label']].rename(columns={'text'+spec+'_M': 'text'})\n",
    "    f_tr = df_train_[['ID', 'text'+spec+'_F', 'label']].rename(columns={'text'+spec+'_F': 'text'})\n",
    "    tr = m_tr.append(f_tr)\n",
    "    tr.to_pickle('Twitter_training/Twitter_mix' + spec + '_train') \n",
    "    \n",
    "    m_te = df_test_[['ID', 'text'+spec+'_M', 'label']].rename(columns={'text'+spec+'_M': 'text'})\n",
    "    f_te = df_test_[['ID', 'text'+spec+'_F', 'label']].rename(columns={'text'+spec+'_F': 'text'})\n",
    "    te = m_te.append(f_te)\n",
    "    te.to_pickle('Twitter_training/Twitter_mix' + spec + '_test') \n",
    "    \n",
    "    print(tr.shape, te.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Sets with no only samples that do not contain any term of the dict\n",
    "dicts are again pron, weat, alll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(691200, 3)\n",
      "(691347, 3)\n",
      "(725866, 3)\n",
      "(725551, 3)\n",
      "(750334, 3)\n",
      "(750541, 3)\n"
     ]
    }
   ],
   "source": [
    "# no term sample\n",
    "\n",
    "df_train_no_pron = df_train_[df_train_['count_total'] == 0][['ID', 'text', 'label']]\n",
    "print(df_train_no_pron.shape)\n",
    "df_test_no_pron = df_test_[df_test_['count_total'] == 0][['ID', 'text', 'label']]\n",
    "print(df_test_no_pron.shape)\n",
    "\n",
    "df_train_no_weat = df_train_[df_train_['count_weat'] == 0][['ID', 'text', 'label']]\n",
    "print(df_train_no_weat.shape)\n",
    "df_test_no_weat = df_test_[df_test_['count_weat'] == 0][['ID', 'text', 'label']]\n",
    "print(df_test_no_weat.shape)\n",
    "\n",
    "df_train_no_all = df_train_[df_train_['count_prons'] == 0][['ID', 'text', 'label']]\n",
    "print(df_train_no_all.shape)\n",
    "df_test_no_all = df_test_[df_test_['count_prons'] == 0][['ID', 'text', 'label']]\n",
    "print(df_test_no_all.shape)\n",
    "\n",
    "\n",
    "df_train_no_pron.to_pickle('Twitter_training/Twitter_no_pron_train')\n",
    "df_test_no_pron.to_pickle('Twitter_training/Twitter_no_pron_test')\n",
    "df_train_no_weat.to_pickle('Twitter_training/Twitter_no_weat_train')\n",
    "df_test_no_weat.to_pickle('Twitter_training/Twitter_no_weat_test')\n",
    "df_train_no_all.to_pickle('Twitter_training/Twitter_no_all_train')\n",
    "df_test_no_all.to_pickle('Twitter_training/Twitter_no_all_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Sets with no only samples that do contain a minimal number of term of the dict\n",
    "dicts are again pron, weat, all  \n",
    "minimal number should most likely be 1 for IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217600, 3) (217306, 3)\n",
      "(99332, 3) (98918, 3)\n",
      "(148268, 3) (148898, 3)\n"
     ]
    }
   ],
   "source": [
    "min_term_count = 1\n",
    "df_train__ = df_train_.rename(columns={'count_total': 'count_all', 'count_prons': 'count_pro'})\n",
    "df_test__ = df_test_.rename(columns={'count_total': 'count_all', 'count_prons': 'count_pro'})\n",
    "\n",
    "\n",
    "for spec in ['_all', '_pro', '_weat']:\n",
    "    \n",
    "    df_train_MIN = df_train__[df_train__['count'+spec] >= min_term_count]\n",
    "    df_test_MIN = df_test__[df_test__['count'+spec] >= min_term_count]\n",
    "    \n",
    "    # all\n",
    "    df_train_MIN[['ID', 'text', 'label']].to_pickle('Twitter_training/Twitter_MIN' + spec + '_test')\n",
    "    df_test_MIN[['ID', 'text', 'label']].to_pickle('Twitter_training/Twitter_MIN' + spec + '_train')\n",
    "    \n",
    "    # neutral M+F\n",
    "    df_train_MIN[['ID', 'text'+spec+'_N', 'label']].to_pickle('Twitter_training/Twitter_MIN_N'+spec+'_train')\n",
    "    df_test_MIN[['ID', 'text'+spec+'_N', 'label']].to_pickle('Twitter_training/Twitter_MIN_N'+spec+'_test')\n",
    "\n",
    "    # mixed\n",
    "    m_tr = df_train_MIN[['ID', 'text'+spec+'_M', 'label']].rename(columns={'text'+spec+'_M': 'text'})\n",
    "    f_tr = df_train_MIN[['ID', 'text'+spec+'_F', 'label']].rename(columns={'text'+spec+'_F': 'text'})\n",
    "    tr = m_tr.append(f_tr)\n",
    "    tr.to_pickle('Twitter_training/Twitter_MIN_mix' + spec + '_train') \n",
    "    \n",
    "    m_te = df_test_MIN[['ID', 'text'+spec+'_M', 'label']].rename(columns={'text'+spec+'_M': 'text'})\n",
    "    f_te = df_test_MIN[['ID', 'text'+spec+'_F', 'label']].rename(columns={'text'+spec+'_F': 'text'})\n",
    "    te = m_te.append(f_te)\n",
    "    te.to_pickle('Twitter_training/Twitter_MIN_mix' + spec + '_test') \n",
    "    \n",
    "    print(tr.shape, te.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
